import os
import torch
import numpy as np
import cv2
import argparse
from tqdm import tqdm
from model import get_model
from data_loader import load_data
import torch.nn.functional as F
import pandas as pd

# Grad-CAM ë¼ì´ë¸ŒëŸ¬ë¦¬: pytorch-grad-cam ì‚¬ìš©
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.image import show_cam_on_image
    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
except ImportError:
    raise ImportError("pytorch-grad-cam ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install grad-cam")

def get_last_conv_layer(model, model_type):
    if model_type == 'resnet50':
        return model.layer4[-1]  # ë§ˆì§€ë§‰ Bottleneck ë¸”ë¡
    elif model_type == 'densenet121':
        return model.features[-2]  # ë§ˆì§€ë§‰ DenseBlock (features[-1]ì€ BatchNorm)
    elif model_type == 'efficientnet_b0':
        return model._conv_head  # ë§ˆì§€ë§‰ conv layer
    else:
        raise ValueError(f"Unknown model type: {model_type}")

def get_experiment_configs():
    configs = [
        # (ì‹¤í—˜ëª…, ëª¨ë¸ ì €ì¥ ê²½ë¡œ, csv, augment ì—¬ë¶€)
        ("cl_basic", "models/cl/{model_type}/basic_cl.pth", "data/meta_info_with_manufacturer_use_split_cl_new.csv", False),
        ("cl_aug",   "models/cl/{model_type}/aug_cl.pth",   "data/meta_info_with_manufacturer_use_split_cl_new.csv", True),
        ("fl_basic", "models/fl/{model_type}/basic_fl.pth", "data/meta_info_with_manufacturer_use_federated_new.csv", False),
        ("fl_aug",   "models/fl/{model_type}/aug_fl.pth",   "data/meta_info_with_manufacturer_use_federated_new.csv", True),
    ]
    return configs

def custom_overlay(image, cam, threshold=0.5, alpha=0.4):
    """
    ì»¤ìŠ¤í…€ overlay í•¨ìˆ˜ - ì„ê³„ê°’ ì ìš©í•˜ì—¬ ê°•í•œ í™œì„±í™” ì˜ì—­ë§Œ í‘œì‹œ
    image: [H, W, 3] RGB ì´ë¯¸ì§€ (0~1)
    cam: [H, W] heatmap (0~1)
    threshold: heatmap ì„ê³„ê°’
    alpha: overlay íˆ¬ëª…ë„
    """
    # ì„ê³„ê°’ ì ìš© - ì„ê³„ê°’ ì´ìƒì¸ ì˜ì—­ë§Œ í‘œì‹œ
    cam_binary = (cam > threshold).astype(np.float32)
    
    # ì„ê³„ê°’ì„ í†µê³¼í•œ ì˜ì—­ì˜ ì›ë³¸ cam ê°’ ìœ ì§€
    cam_thresholded = cam * cam_binary
    
    # heatmapì„ ì»¬ëŸ¬ë¡œ ë³€í™˜
    heatmap = cv2.applyColorMap(np.uint8(255 * cam_thresholded), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    heatmap = heatmap.astype(np.float32) / 255.0
    
    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ 0~255 ë²”ìœ„ë¡œ ë³€í™˜
    image_255 = (image * 255).astype(np.uint8).astype(np.float32)
    
    # overlay - ì„ê³„ê°’ì„ í†µê³¼í•œ ì˜ì—­ì—ë§Œ ì ìš©
    overlay = image_255 * (1 - alpha * cam_binary[..., None]) + \
             heatmap * 255 * alpha * cam_binary[..., None]
    
    return overlay.astype(np.uint8)

def generate_gradcam_image(image_tensor, cam, pred, label, pred_prob, model_name):
    """
    Grad-CAM ì´ë¯¸ì§€ ìƒì„± (ì €ì¥í•˜ì§€ ì•Šê³  numpy array ë°˜í™˜)
    """
    # image_tensor: torch.Tensor [1, H, W] or [H, W]
    # cam: np.ndarray [H, W], 0~1
    image = image_tensor.squeeze().cpu().numpy()  # [H, W]
    image_rgb = np.stack([image]*3, axis=-1)  # [H, W, 3]
    
    # ì»¤ìŠ¤í…€ overlay ì ìš© (ì„ê³„ê°’ 0.5)
    cam_img = custom_overlay(image_rgb, cam, threshold=0.5, alpha=0.4)
    
    # ëª¨ë¸ëª…ê³¼ ì˜ˆì¸¡/ì •ë‹µ ì •ë³´ overlay
    text1 = f"{model_name}"
    text2 = f"Pred: {pred} ({pred_prob:.3f})"
    text3 = f"Label: {label}"
    
    cv2.putText(cam_img, text1, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(cam_img, text2, (5, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)
    cv2.putText(cam_img, text3, (5, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)
    
    return cam_img

def concat_model_results(images_dict, exp_name, dicom_path):
    """
    ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ìˆ˜í‰ìœ¼ë¡œ concat
    images_dict: {model_name: image_array}
    """
    model_names = ['resnet50', 'densenet121', 'efficientnet_b0']
    concat_images = []
    
    for model_name in model_names:
        if model_name in images_dict:
            concat_images.append(images_dict[model_name])
        else:
            # ëª¨ë¸ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ì´ë¯¸ì§€ ìƒì„±
            h, w = 224, 224  # ê¸°ë³¸ í¬ê¸°
            if concat_images:
                h, w = concat_images[0].shape[:2]
            empty_img = np.zeros((h, w, 3), dtype=np.uint8)
            cv2.putText(empty_img, f"{model_name}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (128,128,128), 2)
            cv2.putText(empty_img, "Not Available", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128,128,128), 1)
            concat_images.append(empty_img)
    
    # ìˆ˜í‰ìœ¼ë¡œ concat
    result = np.hstack(concat_images)
    
    # ì‹¤í—˜ëª… ì¶”ê°€
    cv2.putText(result, f"Experiment: {exp_name.upper()}", (10, result.shape[0]-20), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,0), 2, cv2.LINE_AA)
    
    return result

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--device', type=str, default='cuda')
    parser.add_argument('--output_dir', type=str, default='gradcam_results')
    args = parser.parse_args()

    model_types = ['resnet50', 'densenet121', 'efficientnet_b0']
    configs = get_experiment_configs()
    
    # ê° ì‹¤í—˜ë³„ë¡œ ì²˜ë¦¬
    for exp_name, model_path_tpl, csv_path, augment in configs:
        print(f"\nğŸ”¥ Processing experiment: {exp_name}")
        
        # CSV íŒŒì¼ ë¡œë“œí•˜ì—¬ test setì˜ dicom_img_path ê°€ì ¸ì˜¤ê¸°
        df = pd.read_csv(csv_path)
        test_df = df[df['split'] == 'test']
        test_paths = test_df['dicom_img_path'].tolist()
        
        # test set ë¡œë“œ (í•œ ë²ˆë§Œ)
        test_dataset = load_data(csv_path, 'test', augment=False)
        
        # ê²°ê³¼ ì €ì¥ í´ë”
        concat_out_dir = os.path.join(args.output_dir, 'concat', exp_name)
        os.makedirs(concat_out_dir, exist_ok=True)
        
        # ê° ëª¨ë¸ë³„ ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        all_results = {}  # {idx: {model_name: gradcam_image}}
        
        # ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ ì²˜ë¦¬
        for model_type in model_types:
            model_path = model_path_tpl.format(model_type=model_type)
            if not os.path.exists(model_path):
                print(f"  [Skip] {model_type}: model not found at {model_path}")
                continue
            
            print(f"  [Process] {model_type}: {model_path}")
            
            # ëª¨ë¸ ë¡œë“œ
            model = get_model(model_type)
            model.load_state_dict(torch.load(model_path, map_location=args.device))
            model.eval()
            model.to(args.device)
            
            # Grad-CAM ì¤€ë¹„
            target_layer = get_last_conv_layer(model, model_type)
            cam = GradCAM(model=model, target_layers=[target_layer], use_cuda=(args.device=='cuda'))
            
            # test set ìˆœíšŒ
            for idx in tqdm(range(len(test_dataset)), desc=f"  {model_type}"):
                image, label = test_dataset[idx]  # image: [1, H, W]
                input_tensor = image.unsqueeze(0).to(args.device)  # [1, 1, H, W]
                
                # ëª¨ë¸ ì˜ˆì¸¡
                with torch.no_grad():
                    output = model(input_tensor)
                    probs = F.softmax(output, dim=1)
                    pred = torch.argmax(probs, dim=1).item()
                    pred_prob = probs[0, pred].item()
                
                # Grad-CAM ìƒì„±
                targets_pred = [ClassifierOutputTarget(pred)]
                grayscale_cam_pred = cam(input_tensor=input_tensor, targets=targets_pred)[0]  # [H, W], 0~1
                
                # Grad-CAM ì´ë¯¸ì§€ ìƒì„±
                gradcam_img = generate_gradcam_image(image, grayscale_cam_pred, pred, label, pred_prob, model_type.upper())
                
                # ê²°ê³¼ ì €ì¥
                if idx not in all_results:
                    all_results[idx] = {}
                all_results[idx][model_type] = gradcam_img
        
        # ê° ì´ë¯¸ì§€ë³„ë¡œ ëª¨ë¸ ê²°ê³¼ concatí•˜ì—¬ ì €ì¥
        print(f"  [Concat] Creating concatenated images...")
        for idx in tqdm(range(len(test_dataset)), desc=f"  Concat {exp_name}"):
            if idx in all_results and all_results[idx]:  # ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                dicom_path = test_paths[idx].replace('/', '_').replace('\\', '_')
                
                # ëª¨ë¸ë³„ ê²°ê³¼ concat
                concat_img = concat_model_results(all_results[idx], exp_name, dicom_path)
                
                # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥
                out_path = os.path.join(concat_out_dir, f"{dicom_path}.png")
                cv2.imwrite(out_path, concat_img)
        
        print(f"  âœ… {exp_name} completed!")
            
    print("\nğŸ‰ ëª¨ë“  Grad-CAM concat ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 