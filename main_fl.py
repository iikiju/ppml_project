import torch
from model import get_model
from data_loader import load_data
from dp_utils import attach_dp, fix_model_for_dp, calculate_epsilon, estimate_global_epsilon, compute_rdp_to_dp, get_privacy_level
from train_utils import train_one_epoch, evaluate
import torch.nn as nn
import torch.optim as optim
import copy
import os
from tqdm import tqdm
import pandas as pd
import argparse
import numpy as np
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, f1_score
import json
from datetime import datetime
import random

def set_seed(seed):
    """ì¬í˜„ì„±ì„ ìœ„í•´ ëœë¤ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # ë©€í‹° GPU ì‚¬ìš© ì‹œ
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)
    print(f"ğŸ”’ ëœë¤ ì‹œë“œ ê³ ì •ë¨: {seed}")

def average_weights(w):
    """
    Returns the average of the weights from all clients.
    Handles different data types safely to prevent casting errors.
    """
    if not w:
        raise ValueError("ê°€ì¤‘ì¹˜ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    w_avg = copy.deepcopy(w[0])
    
    for key in w_avg.keys():
        # ì°¸ì¡° í…ì„œì˜ ì†ì„± í™•ì¸
        reference_tensor = w[0][key]
        tensor_dtype = reference_tensor.dtype
        tensor_device = reference_tensor.device
        
        # ì •ìˆ˜í˜• íƒ€ì…ì¸ì§€ í™•ì¸
        is_integer_type = tensor_dtype in [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8]
        
        # í‰ê·  ê³„ì‚°ì„ ìœ„í•œ ì´ˆê¸°í™”
        if is_integer_type:
            # ì •ìˆ˜í˜•ì˜ ê²½ìš° floatë¡œ ê³„ì‚°
            w_avg[key] = w[0][key].float()
        else:
            w_avg[key] = w[0][key].clone()
        
        # ë‚˜ë¨¸ì§€ ê°€ì¤‘ì¹˜ë“¤ì„ ë”í•¨
        for i in range(1, len(w)):
            try:
                current_tensor = w[i][key].to(device=tensor_device)
                if is_integer_type:
                    w_avg[key] += current_tensor.float()
                else:
                    w_avg[key] += current_tensor.to(dtype=tensor_dtype)
            except Exception as e:
                print(f"âš ï¸ í‚¤ {key}ì—ì„œ ê°€ì¤‘ì¹˜ í•©ì‚° ì˜¤ë¥˜: {e}")
                continue
        
        # í‰ê·  ê³„ì‚°
        try:
            w_avg[key] = torch.div(w_avg[key], len(w))
            
            # ì •ìˆ˜í˜•ì˜ ê²½ìš° ì›ë˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            if is_integer_type:
                w_avg[key] = w_avg[key].round().to(dtype=tensor_dtype)
            else:
                w_avg[key] = w_avg[key].to(dtype=tensor_dtype)
                
        except Exception as e:
            print(f"âš ï¸ í‚¤ {key}ì—ì„œ í‰ê·  ê³„ì‚° ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì²« ë²ˆì§¸ í´ë¼ì´ì–¸íŠ¸ì˜ ê°€ì¤‘ì¹˜ ì‚¬ìš©
            w_avg[key] = w[0][key].clone()
    
    return w_avg

def train_federated(args):
    # ëœë¤ ì‹œë“œ ì„¤ì •
    if args.seed is not None:
        set_seed(args.seed)
    
    # CSV íŒŒì¼ì—ì„œ ê³ ìœ  í´ë¼ì´ì–¸íŠ¸ ID ì¶”ì¶œ
    df = pd.read_csv(args.csv)
    
    # ìœ íš¨í•œ í´ë¼ì´ì–¸íŠ¸ IDë§Œ ì¶”ì¶œ (nan ì œì™¸, ë¬¸ìì—´ë¡œ ë³€í™˜)
    train_df = df[df['split'] == 'train']
    if 'client_id' not in train_df.columns:
        raise ValueError("client_id ì—´ì´ CSV íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
    
    # NaN ê°’ì„ ì œì™¸í•˜ê³  ìœ íš¨í•œ client IDë§Œ ì¶”ì¶œ
    client_ids = [str(cid) for cid in train_df['client_id'].unique() if str(cid) != 'nan' and pd.notna(cid)]
    
    if not client_ids:
        raise ValueError("ìœ íš¨í•œ client_idê°€ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    
    print(f"ğŸ” ë°œê²¬ëœ í´ë¼ì´ì–¸íŠ¸ ID: {', '.join(client_ids)}")
    
    # ëª¨ë¸ ìƒì„±
    global_model = get_model(args.model).to(args.device)
    
    # DPë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ëª¨ë¸ ìˆ˜ì •
    if args.dp:
        print("ğŸ”’ DP ëª¨ë¸ë¡œ ë³€í™˜ ì¤‘...")
        global_model = fix_model_for_dp(global_model)
    
    # í”„ë¼ì´ë²„ì‹œ ì˜ˆì‚° ì¶”ì ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
    privacy_logs = {
        'rounds': [],
        'noise_multiplier': args.noise,
        'max_grad_norm': args.max_grad_norm,
        'delta': args.delta,
        'target_epsilon': args.target_epsilon
    }
    
    # í•™ìŠµ ì‹œì‘
    for round_idx in range(args.rounds):
        print(f"\n=== ë¼ìš´ë“œ {round_idx+1}/{args.rounds} ===")
        
        # í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        local_weights = []
        local_sizes = []
        local_epsilons = []
        
        round_clients = {}
        
        # ê° í´ë¼ì´ì–¸íŠ¸ì—ì„œ í•™ìŠµ
        for client_id in client_ids:
            print(f"\nğŸ‘¤ í´ë¼ì´ì–¸íŠ¸ {client_id} í•™ìŠµ ì¤‘...")
            
            # ë°ì´í„° ë¡œë“œ
            train_dataset = load_data(args.csv, 'train', client_id=client_id, augment=args.augment)
            train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
            print(f"ğŸ“Š í´ë¼ì´ì–¸íŠ¸ {client_id}ì˜ ë°ì´í„° í¬ê¸°: {len(train_dataset)}")
            
            # í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ ì´ˆê¸°í™” (ê¸€ë¡œë²Œ ëª¨ë¸ ë³µì‚¬)
            local_model = get_model(args.model).to(args.device)
            
            # DPë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ëª¨ë¸ ìˆ˜ì •
            if args.dp:
                local_model = fix_model_for_dp(local_model)
                # ê¸€ë¡œë²Œ ëª¨ë¸ë„ DP í˜¸í™˜ ë²„ì „ìœ¼ë¡œ ë³€í™˜ (ì²« ë¼ìš´ë“œì¸ ê²½ìš°)
                if round_idx == 0:
                    global_model = fix_model_for_dp(global_model)
            
            # ê¸€ë¡œë²Œ ëª¨ë¸ì—ì„œ ìƒíƒœ ë³µì‚¬ (DP ë³€í™˜ í›„)
            local_model.load_state_dict(global_model.state_dict())
            
            # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
            optimizer = optim.Adam(local_model.parameters(), lr=args.lr)
            criterion = nn.CrossEntropyLoss()
            
            # í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ì´ˆê¸°í™”
            client_info = {
                'data_size': len(train_dataset),
                'epsilon': None,
                'privacy_engine': None
            }
            
            # ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°
            sampling_rate = args.batch_size / len(train_dataset)
            
            # DPë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í”„ë¼ì´ë²„ì‹œ ì—”ì§„ ì„¤ì •
            if args.dp:
                try:
                    local_model, optimizer, train_loader, privacy_engine = attach_dp(
                        local_model, 
                        optimizer, 
                        train_loader,
                        noise_multiplier=args.noise,
                        max_grad_norm=args.max_grad_norm,
                        device=args.device
                    )
                    client_info['privacy_engine'] = privacy_engine
                    print(f"ğŸ”’ DP ì ìš©ë¨ (noise={args.noise}, max_grad_norm={args.max_grad_norm}, ìƒ˜í”Œë§ ë¹„ìœ¨={sampling_rate:.4f})")
                except Exception as e:
                    print(f"âŒ DP ì ìš© ì‹¤íŒ¨: {e}")
                    print("âš ï¸ DP ì—†ì´ ê³„ì†í•©ë‹ˆë‹¤")
            
            # ë¡œì»¬ ëª¨ë¸ í•™ìŠµ
            for epoch in range(args.local_epochs):
                train_loss = train_one_epoch(local_model, train_loader, optimizer, criterion, args.device)
                print(f"ğŸ“ˆ ì—í­ {epoch+1}/{args.local_epochs}, ì†ì‹¤: {train_loss:.4f}")
            
            # ì—í­ ì™„ë£Œ í›„ epsilon ê³„ì‚°
            if args.dp and client_info['privacy_engine'] is not None:
                # Opacusë¡œ epsilon ê³„ì‚° ì‹œë„
                client_epsilon = calculate_epsilon(
                    client_info['privacy_engine'], 
                    sample_rate=sampling_rate,
                    epochs=args.local_epochs,
                    delta=args.delta
                )
                
                # ê³„ì‚° ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ê³„ì‚°
                if client_epsilon is None:
                    print("ğŸ”„ ìˆ˜ë™ìœ¼ë¡œ epsilon ê³„ì‚° ì‹œë„ ì¤‘...")
                    steps = args.local_epochs / sampling_rate
                    client_epsilon = compute_rdp_to_dp(
                        noise_multiplier=args.noise,
                        sample_rate=sampling_rate,
                        steps=steps,
                        delta=args.delta
                    )
                    print(f"ğŸ“Š ìˆ˜ë™ ê³„ì‚°ëœ DP ë§¤ê°œë³€ìˆ˜: (Îµ={client_epsilon:.4f}, Î´={args.delta})")
                
                client_info['epsilon'] = client_epsilon
                
                if client_epsilon is not None:
                    print(f"ğŸ”’ í´ë¼ì´ì–¸íŠ¸ {client_id}ì˜ Îµ ê°’: {client_epsilon:.4f}")
                    # epsilon ê°’ì˜ í”„ë¼ì´ë²„ì‹œ ìˆ˜ì¤€ í‘œì‹œ
                    privacy_level = get_privacy_level(client_epsilon)
                    print(f"ğŸ”’ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ìˆ˜ì¤€: {privacy_level}")
                    
                    # ëª©í‘œ epsilonê³¼ ë¹„êµ
                    if args.target_epsilon and client_epsilon > args.target_epsilon:
                        print(f"âš ï¸ ì£¼ì˜: í˜„ì¬ Îµ ê°’ ({client_epsilon:.4f})ì´ ëª©í‘œ Îµ ê°’ ({args.target_epsilon:.4f})ë³´ë‹¤ í½ë‹ˆë‹¤.")
                    
                    local_epsilons.append(client_epsilon)
                else:
                    print(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id}ì˜ Îµ ê°’ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    local_epsilons.append(None)
            
            # í´ë¼ì´ì–¸íŠ¸ ê°€ì¤‘ì¹˜ ìˆ˜ì§‘
            local_weights.append(local_model.state_dict())
            local_sizes.append(len(train_dataset))
            round_clients[client_id] = client_info
        
        # ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ (ê°€ì¤‘ì¹˜ í‰ê· )
        with torch.no_grad():
            # ë°ì´í„° í¬ê¸°ì— ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜ ê³„ì‚°
            total_size = sum(local_sizes)
            weights = [size / total_size for size in local_sizes]
            
            # ê¸€ë¡œë²Œ ëª¨ë¸ì˜ ê° íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
            try:
                # ëª¨ë“  ë¡œì»¬ ëª¨ë¸ì´ ì¼ê´€ëœ í‚¤ë¥¼ ê°€ì§€ëŠ”ì§€ í™•ì¸
                keys_set = [set(w.keys()) for w in local_weights]
                common_keys = set.intersection(*keys_set)
                
                if not common_keys:
                    raise ValueError("ë¡œì»¬ ëª¨ë¸ë“¤ ê°„ì— ê³µí†µëœ íŒŒë¼ë¯¸í„° í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ëª¨ë“  ëª¨ë¸ì´ DPë¡œ ë³€í™˜ë˜ë©´ì„œ ì¼ë¶€ í‚¤ê°€ ë³€ê²½ë  ìˆ˜ ìˆìŒ
                # ì¼ê´€ëœ í‚¤ ì§‘í•©ì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ í‰ê·  ê³„ì‚°
                global_weights = {}
                for key in common_keys:
                    # ê° í…ì„œì˜ ì›ë˜ ë°ì´í„° íƒ€ì…ê³¼ ë””ë°”ì´ìŠ¤ ë³´ì¡´
                    reference_tensor = local_weights[0][key]
                    tensor_dtype = reference_tensor.dtype
                    tensor_device = reference_tensor.device
                    
                    # ì •ìˆ˜í˜• íƒ€ì…ì¸ì§€ í™•ì¸ (ì˜ˆ: Long, Int ë“±)
                    is_integer_type = tensor_dtype in [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8]
                    
                    # ê°€ì¤‘ í‰ê·  ê³„ì‚°ì„ ìœ„í•œ ì´ˆê¸°í™”
                    if is_integer_type:
                        # ì •ìˆ˜í˜• íŒŒë¼ë¯¸í„°ì˜ ê²½ìš° floatë¡œ ê³„ì‚° í›„ ë‹¤ì‹œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
                        global_weights[key] = torch.zeros_like(reference_tensor, dtype=torch.float32, device=tensor_device)
                    else:
                        global_weights[key] = torch.zeros_like(reference_tensor, dtype=tensor_dtype, device=tensor_device)
                    
                    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                    for i in range(len(local_weights)):
                        local_tensor = local_weights[i][key].to(device=tensor_device)
                        if is_integer_type:
                            # ì •ìˆ˜í˜•ì˜ ê²½ìš° floatë¡œ ë³€í™˜í•˜ì—¬ ê³„ì‚°
                            global_weights[key] += weights[i] * local_tensor.float()
                        else:
                            global_weights[key] += weights[i] * local_tensor.to(dtype=tensor_dtype)
                    
                    # ìµœì¢… ê°€ì¤‘ì¹˜ë¥¼ ì›ë˜ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    if is_integer_type:
                        # ì •ìˆ˜í˜•ì˜ ê²½ìš° ë°˜ì˜¬ë¦¼ í›„ ì›ë˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                        global_weights[key] = global_weights[key].round().to(dtype=tensor_dtype)
                    else:
                        # ë¶€ë™ì†Œìˆ˜ì í˜•ì˜ ê²½ìš° ì›ë˜ íƒ€ì… ìœ ì§€
                        global_weights[key] = global_weights[key].to(dtype=tensor_dtype)
                
                # ëª¨ë¸ ì—…ë°ì´íŠ¸
                missing_keys, unexpected_keys = global_model.load_state_dict(global_weights, strict=False)
                
                if missing_keys:
                    print(f"âš ï¸ ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì¤‘ ëˆ„ë½ëœ í‚¤: {missing_keys}")
                if unexpected_keys:
                    print(f"âš ï¸ ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜ˆìƒì¹˜ ì•Šì€ í‚¤: {unexpected_keys}")
            
            except Exception as e:
                print(f"âŒ ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                print("âš ï¸ ì²« ë²ˆì§¸ í´ë¼ì´ì–¸íŠ¸ì˜ ê°€ì¤‘ì¹˜ë¡œ í´ë°±í•©ë‹ˆë‹¤")
                try:
                    # í´ë°± ì‹œì—ë„ ì•ˆì „í•œ ë¡œë”©
                    global_model.load_state_dict(local_weights[0], strict=False)
                except Exception as fallback_error:
                    print(f"âŒ í´ë°± ë¡œë”©ë„ ì‹¤íŒ¨: {str(fallback_error)}")
                    # ë” ì•ˆì „í•œ í´ë°±: í‚¤ë³„ë¡œ ê°œë³„ ì²˜ë¦¬
                    for key, value in local_weights[0].items():
                        try:
                            if key in global_model.state_dict():
                                global_model.state_dict()[key].copy_(value)
                        except Exception as key_error:
                            print(f"âš ï¸ í‚¤ {key} ë³µì‚¬ ì‹¤íŒ¨: {str(key_error)}")
                            continue
        
        # ê¸€ë¡œë²Œ epsilon ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
        global_epsilon = None
        if args.dp and local_epsilons:
            global_epsilon = estimate_global_epsilon(local_epsilons, weights)
            if global_epsilon is not None:
                print(f"ğŸ”’ ë¼ìš´ë“œ {round_idx+1}ì˜ ê¸€ë¡œë²Œ Îµ ì¶”ì •ê°’: {global_epsilon:.4f}")
                # ê¸€ë¡œë²Œ epsilon ê°’ì˜ í”„ë¼ì´ë²„ì‹œ ìˆ˜ì¤€ í‘œì‹œ
                privacy_level = get_privacy_level(global_epsilon)
                print(f"ğŸ”’ ê¸€ë¡œë²Œ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ìˆ˜ì¤€: {privacy_level}")
                
                # ëª©í‘œ epsilonê³¼ ë¹„êµ
                if args.target_epsilon and global_epsilon > args.target_epsilon:
                    print(f"âš ï¸ ì£¼ì˜: ê¸€ë¡œë²Œ Îµ ê°’ ({global_epsilon:.4f})ì´ ëª©í‘œ Îµ ê°’ ({args.target_epsilon:.4f})ë³´ë‹¤ í½ë‹ˆë‹¤.")
            else:
                print(f"âš ï¸ ë¼ìš´ë“œ {round_idx+1}ì˜ ê¸€ë¡œë²Œ Îµ ê°’ì„ ì¶”ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë¼ìš´ë“œ ì •ë³´ ì €ì¥
        round_info = {
            'round': round_idx + 1,
            'clients': {
                client_id: {
                    'data_size': info['data_size'],
                    'epsilon': info['epsilon']
                } for client_id, info in round_clients.items()
            },
            'global_epsilon': global_epsilon if args.dp else None,
            'weights': weights
        }
        privacy_logs['rounds'].append(round_info)
        
        print(f"âœ… ë¼ìš´ë“œ {round_idx+1} ì™„ë£Œ: ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ë¨")
    
    # ëª¨ë¸ ì €ì¥
    if args.save_path:
        torch.save(global_model.state_dict(), args.save_path)
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ë¨: {args.save_path}")
        
        # í”„ë¼ì´ë²„ì‹œ ë¡œê·¸ ì €ì¥
        if args.dp:
            log_dir = os.path.dirname(args.save_path)
            if not log_dir:
                log_dir = '.'
            model_name = os.path.splitext(os.path.basename(args.save_path))[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            privacy_log_path = f"{log_dir}/{model_name}_privacy_{timestamp}.json"
            
            with open(privacy_log_path, 'w') as f:
                json.dump(privacy_logs, f, indent=2, default=lambda x: None if not isinstance(x, (int, float, str, bool, list, dict)) else str(x))
            print(f"ğŸ“Š í”„ë¼ì´ë²„ì‹œ ë¡œê·¸ ì €ì¥ë¨: {privacy_log_path}")
    
    return global_model

def test_federated(args, model=None):
    # ëœë¤ ì‹œë“œ ì„¤ì •
    if args.seed is not None:
        set_seed(args.seed)
    
    # ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ì‚¬ìš©
    if model is None:
        model = get_model(args.model).to(args.device)
        
        # ë§Œì•½ DP ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ê²½ìš°, ë¨¼ì € ëª¨ë¸ì„ DP í˜¸í™˜ë˜ê²Œ ë³€í™˜
        if args.dp or ".pth" in args.load_path and any(dp_term in args.load_path for dp_term in ["dp", "DP"]):
            print("ğŸ”’ DP í˜¸í™˜ ëª¨ë¸ë¡œ ë³€í™˜í•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤...")
            model = fix_model_for_dp(model)
            
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ì„¤ì •í•˜ì—¬ í‚¤ ë¶ˆì¼ì¹˜ í—ˆìš©)
        state_dict = torch.load(args.load_path, map_location=args.device)
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
        
        if missing_keys:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì¤‘ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
        if unexpected_keys:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ì•Šì€ í‚¤: {len(unexpected_keys)}ê°œ")
            
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œë¨: {args.load_path}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ - client_id ì—†ì´ ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©
    test_dataset = load_data(args.csv, 'test', client_id=None, augment=False)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_dataset)} ìƒ˜í”Œ")
    
    # ì „ì²´ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    test_loss, preds, targets = evaluate(model, test_loader, nn.CrossEntropyLoss(), args.device)
    overall_accuracy = accuracy_score(targets, preds)
    overall_f1 = f1_score(targets, preds, average='weighted')
    
    print("\n=== ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    print(f"ì „ì²´ ì •í™•ë„: {overall_accuracy:.4f}")
    print(f"ì „ì²´ F1 ì ìˆ˜: {overall_f1:.4f}")
    
    # DP ì ìš© ëª¨ë¸ì¸ ê²½ìš° epsilon ì •ë³´ í‘œì‹œ
    if args.dp and args.target_epsilon:
        print(f"ğŸ”’ ëª©í‘œ Îµ ê°’: {args.target_epsilon} (Î´={args.delta})")
    
    # ê° í´ë¼ì´ì–¸íŠ¸ë³„ í…ŒìŠ¤íŠ¸ (í´ë¼ì´ì–¸íŠ¸ IDê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    df = pd.read_csv(args.csv)
    client_metrics = {}
    
    # í´ë¼ì´ì–¸íŠ¸ IDê°€ ìˆëŠ”ì§€ í™•ì¸
    if 'client_id' in df.columns:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— í´ë¼ì´ì–¸íŠ¸ IDê°€ ìˆëŠ”ì§€ í™•ì¸
        test_df = df[df['split'] == 'test']
        has_client_ids = 'client_id' in test_df.columns and not test_df['client_id'].isna().all()
        
        if has_client_ids:
            # ìœ íš¨í•œ í´ë¼ì´ì–¸íŠ¸ IDë§Œ ì¶”ì¶œ
            client_ids = [str(cid) for cid in test_df['client_id'].unique() if str(cid) != 'nan' and pd.notna(cid)]
            
            if client_ids:
                print("\n=== í´ë¼ì´ì–¸íŠ¸ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
                
                for client_id in client_ids:
                    # í´ë¼ì´ì–¸íŠ¸ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
                    client_test_dataset = load_data(args.csv, 'test', client_id=client_id, augment=False)
                    
                    if len(client_test_dataset) > 0:
                        client_test_loader = DataLoader(client_test_dataset, batch_size=args.batch_size, shuffle=False)
                        
                        # í‰ê°€
                        test_loss, preds, targets = evaluate(model, client_test_loader, nn.CrossEntropyLoss(), args.device)
                        accuracy = accuracy_score(targets, preds)
                        f1 = f1_score(targets, preds, average='weighted')
                        
                        print(f"ğŸ‘¤ í´ë¼ì´ì–¸íŠ¸ {client_id} ê²°ê³¼:")
                        print(f"   ì†ì‹¤: {test_loss:.4f}, ì •í™•ë„: {accuracy:.4f}, F1 ì ìˆ˜: {f1:.4f}")
                        
                        client_metrics[client_id] = {
                            'loss': test_loss,
                            'accuracy': accuracy,
                            'f1': f1,
                            'samples': len(client_test_dataset)
                        }
    
    return overall_accuracy, overall_f1, client_metrics

def main():
    parser = argparse.ArgumentParser(description='Federated Learning for Medical Imaging')
    parser.add_argument('--csv', type=str, default='data/meta_info_with_manufacturer_use_federated_new.csv',
                        help='CSV file with dataset information')
    parser.add_argument('--model', type=str, default='resnet50',
                       choices=['resnet50', 'densenet121', 'efficientnet_b0'],
                       help='Model architecture')
    parser.add_argument('--rounds', type=int, default=5, help='Number of federated rounds')
    parser.add_argument('--local_epochs', type=int, default=2, help='Number of local epochs')
    parser.add_argument('--batch_size', type=int, default=16, help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                        help='Device to use (cuda/cpu)')
    parser.add_argument('--save_path', type=str, default=None, help='Path to save model')
    parser.add_argument('--load_path', type=str, default=None, help='Path to load model for testing')
    parser.add_argument('--test_only', action='store_true', help='Only test the model')
    parser.add_argument('--dp', action='store_true', help='Use differential privacy')
    parser.add_argument('--noise', type=float, default=1.0, help='Noise multiplier for DP')
    parser.add_argument('--max_grad_norm', type=float, default=1.0, help='Max gradient norm for DP')
    parser.add_argument('--delta', type=float, default=1e-5, help='Delta parameter for DP privacy guarantees')
    parser.add_argument('--target_epsilon', type=float, default=None, help='Target epsilon value for DP')
    parser.add_argument('--augment', action='store_true', help='Use data augmentation')
    parser.add_argument('--seed', type=int, default=None, help='Random seed for reproducibility')
    
    args = parser.parse_args()
    
    # ëª¨ë¸ í•™ìŠµ ë˜ëŠ” í…ŒìŠ¤íŠ¸
    if args.test_only:
        if args.load_path is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ì „ìš© ëª¨ë“œì—ì„œëŠ” --load_pathê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return
        test_federated(args)
    else:
        # ëª¨ë¸ í•™ìŠµ
        model = train_federated(args)
        # í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        test_federated(args, model)

if __name__ == "__main__":
    main()